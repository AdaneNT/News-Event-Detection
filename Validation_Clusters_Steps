Algorithm  for evaluating the stability of clustering solutions 

Representations:
    -	F = { λx : x= 1,..., f }: The set of all features in a given dataset
    -	f = |F|: The number of features in a dataset
    -	k: The number of samples in the validation procedure
    -	C: The number of clusters generated by the clustering algorithm 
    -	y_m, m = 1,…, f: the estimated similarity score of the m_th feature in the training dataset assigned to cluster i 
    -	y^_m , m = 1,…, f: the estimated similarity score of the m_th feature   in the testing dataset assigned to cluster i  
1. Data Preparation:
    a.	Scrap data from the web (e.g GDELT)
    b.	Clean and preprocess the dataset.
2. Dataset Manipulation:
    a.	Randomly shuffle the original dataset.
    b.	Split the original dataset into k parts (folds).
3. Cross-validation Loop:
    a. For each fold j=1,...,k:
        I.	Take fold j as the test dataset (each fold, in turn, is used as the test dataset).
        II.	Take the remaining samples/folds together as the training dataset.
        III.  Generate keywords using KeyBERT/KeyLLM on each sample (step I and II).
        IV.	Refine and remove duplicated keywords/phrases.
        V.	Represent the generated keywords using LLM embedding.
        VI.	Reduce the size of the embedding via UMAP/t-SNE.
        VII. Generate clusters on the reduced version of the training dataset.
        VIII. Assign points from the test data to the corresponding clusters in step vii.
    b. For each cluster i = 1, …, C:
        I.	Compute (sum up) the similarity scores, y_m  , m = 1,…, f,  of the features in cluster i of the samples in the training dataset. 
        II.	Compute (sum up) the estimated similarity scores, y^_m  , m = 1,…, f,  of the features in cluster i of the samples in the test dataset.
        III. Compute the root mean squared error (RMSE) between the training and testing (obtained in I and II in the previous steps) for cluster i. 
4. Record the final scores:
    a.	Once the loop in step 3 finishes: 
        -	Note down the errors as a quality measure for cluster i obtained in fold j. 
        -	Compute the average scores for each cluster across all the folds.
        -	Determine the global mean scores of all clusters across all samples.
