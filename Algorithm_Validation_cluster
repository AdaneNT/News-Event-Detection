Algorithm  for evaluating the stability of clustering solutions 

Representations:
    -	F = { λi : i= 1,..., f }: The set of all features in a given dataset
    -	f = |F|: The number of features in a dataset
    -	k: The number of samples in the validation procedure
    -	C: The number of clusters generated by the clustering algorithm 
    -	 , m = 1,…, f: the probability (percentage) that a data point from the training dataset assigned to cluster i has the m_th  feature 
    -	 , m = 1,…, f: the probability (percentage) that a data point from the testing dataset assigned to cluster i has the m_th feature
    1. Data Preparation:
      a.	Scrap data from the web (e.g GDELT)
      b.	Clean and preprocess the dataset.
      2. Dataset Manipulation:
      a.	Randomly shuffle the original dataset.
      b.	Split the original dataset into k parts (folds).
3. Cross-validation Loop:
         a. For each fold j=1,...,k:
      I.	 Take fold j as the test dataset (each fold, in turn, is used as the test dataset).
      II.	 Take the remaining samples/folds together as the training dataset.
      III.	 Generate keywords using KeyBERT/KeyLLM on I and II.
      IV.	 Refine and remove duplicated keywords/phrases.
      V.	 Represent the generated keywords using LLM embedding.
      VI.	 Reduce the size of the embedding via UMAP/t-SNE.
      VII.	 Apply normalization to the embedding if needed.
      VIII.	 Generate clusters on the reduced version of the training dataset.
      IX.	 Assign points from the test data to the corresponding clusters in step vii.
    b. For each cluster i = 1, …, C:
      I.	Compute the empirical probabilities  , m = 1,…, f  of the occurrence of the features in cluster i based on the samples in the training dataset. 
      II.	Compute the probabilities  , m = 1,…, f of the occurrence of the features in cluster i using the assignment of the points from the test dataset to the clusters.
      III.	Compute the root mean squared error (RMSE) between the probabilities calculated in steps 1 and 2 (in the previous steps). 
4. Record the final scores:
    a.	Once the loop in step 3 finishes: 
    -	Note down the errors as a quality measure for cluster i obtained in fold j. 
    -	Compute the average scores for each cluster across all the folds.
    -	Determine the global mean scores of all clusters across all samples.
