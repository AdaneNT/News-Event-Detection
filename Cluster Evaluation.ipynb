{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e543213e-d3fe-46d9-80f2-e6b102fde826",
   "metadata": {},
   "source": [
    "###  Cluster Creation and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e18dab-7d9f-496a-b2c5-b674d7622537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df1=keys_df.loc[:,['key', 'score', 'LLM_embedding', 'key_umap']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa5af2-f36a-4915-be1e-e6815b503e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "import prince\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a4ea3-c4da-4516-99b8-85dc7f2f0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize clustering and partitioning\n",
    "kmeans = KMeans(n_clusters=6,init='k-means++', max_iter=300, n_init=10) \n",
    "cv = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "\n",
    "counter=0\n",
    "#Split data into 5 or 10 partitions\n",
    "for train_index, test_index in cv.split(df1):\n",
    "    X_train, X_test = df1.iloc[train_index], df1.iloc[test_index]\n",
    "    \n",
    "    # Convert strings representing lists to actual lists of floats (if required)\n",
    "    X_train[\"key_umap\"] = X_train[\"key_umap\"].apply(lambda x: [float(val) for val in x.strip('][').split(', ')])\n",
    "    X_test[\"key_umap\"] = X_test[\"key_umap\"].apply(lambda x: [float(val) for val in x.strip('][').split(', ')])\n",
    "\n",
    "    #print(X_train.shape)\n",
    "    # Take only the scores/features for both testing and training\n",
    "    X_train= X_train[['key', 'score', 'ada_embedding', 'key_umap']]\n",
    "    X_test= X_test[['key', 'score', 'ada_embedding', 'key_umap']]\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    embedding_values_array = np.array(X_train[\"key_umap\"].tolist())\n",
    "    \n",
    "    # Reduce dimensionality using UMAP\n",
    "    umap_embedding = umap.UMAP().fit_transform(embedding_values_array)\n",
    "   \n",
    "    # Apply KMeans clustering with UMAP\n",
    "    #kmeans = KMeans(n_clusters=5, random_state=0)  # You may adjust the number of clusters as needed\n",
    "    labels = kmeans.fit_predict(umap_embedding)\n",
    "    X_train[\"label\"] = [str(label) for label in labels]\n",
    "    #print(f\"Num of clusters: {len(np.unique(labels))}\")\n",
    "    \n",
    "    #Model fit with Testing data\n",
    "    embedding_values_array_test = np.array(X_test[\"key_umap\"].tolist())\n",
    "    # Reduce dimensionality using UMAP\n",
    "    umap_embedding_test = umap.UMAP().fit_transform(embedding_values_array_test)\n",
    "    y_pred_test=kmeans.predict(umap_embedding_test)\n",
    "    X_test[\"label\"] = [str(label) for label in y_pred_test]\n",
    "    #print(f\"Num of clusters: {len(np.unique(labels))}\")  \n",
    "\n",
    "    # Calculate the sum of values in \"key_umap\" for each row\n",
    "    X_train['sum_umap_train'] = X_train['key_umap'].apply(np.sum)\n",
    "    X_test['sum_umap_train'] = X_test['key_umap'].apply(np.sum)\n",
    "    \n",
    "    # incude the sum of key_umap as new column\n",
    "    Xtrain=X_train[['score','label', 'sum_umap_train']]\n",
    "    Xtest=X_test[['score','label', 'sum_umap_train']]\n",
    "\n",
    "    #Train :  group and sum values of each cluster on train\n",
    "    Xtrain=Xtrain.groupby(['label']).sum()\n",
    "    Xtrain2=Xtrain.T\n",
    "    Xtrain2.columns=['c0', 'c1', 'c2', 'c3', 'c4','c5'];\n",
    "    #Xtrain2.columns=['c0', 'c1', 'c2'];\n",
    "    Xtrain3=Xtrain2.T\n",
    "    \n",
    "    # Test: group and sum values of each cluster  on test\n",
    "    Xtest=Xtest.groupby(['label']).sum()\n",
    "    Xtest2=Xtest.T\n",
    "    Xtest2.columns=['c0', 'c1', 'c2','c3', 'c4','c5'];\n",
    "    Xtest3=Xtest2.T\n",
    "\n",
    "    #Total sum of clusters on train\n",
    "    Xtrain3_sums = Xtrain3.sum(axis=0)\n",
    "    \n",
    "    # Train: Normalize values by dividing the values of each cluster by the total number \n",
    "    ct0=pd.Series(Xtrain3.iloc[0]/Xtrain3_sums)\n",
    "    ct1=pd.Series(Xtrain3.iloc[1]/Xtrain3_sums)\n",
    "    ct2=pd.Series(Xtrain3.iloc[2]/Xtrain3_sums)\n",
    "    ct3=pd.Series(Xtrain3.iloc[3]/Xtrain3_sums)\n",
    "    ct4=pd.Series(Xtrain3.iloc[4]/Xtrain3_sums)\n",
    "    ct5=pd.Series(Xtrain3.iloc[5]/Xtrain3_sums)\n",
    " \n",
    "\n",
    "    #Join clusters as columns and rename\n",
    "    df_per_train=pd.concat([ct0,ct1,ct2,ct3,ct4,ct5],axis=1)\n",
    "    df_per_train.columns = ['c0', 'c1', 'c2','c3', 'c4','c5']\n",
    "    #df_per_test=df_per_train.T\n",
    "    df_per_train\n",
    "\n",
    "    #Total sum of clusters on Test\n",
    "    Xtest3_sums = Xtest3.sum(axis=0)\n",
    "    \n",
    "    # # Test: Normalize values by dividing the values of each cluster by the total number \n",
    "    c00=pd.Series(Xtest3.iloc[0]/Xtest3_sums)\n",
    "    c10=pd.Series(Xtest3.iloc[1]/Xtest3_sums)\n",
    "    c20=pd.Series(Xtest3.iloc[2]/Xtest3_sums)\n",
    "    c30=pd.Series(Xtest3.iloc[3]/Xtest3_sums)\n",
    "    c40=pd.Series(Xtest3.iloc[4]/Xtest3_sums)\n",
    "    c50=pd.Series(Xtest3.iloc[5]/Xtest3_sums)\n",
    "\n",
    "    #Join clusters as columns and rename\n",
    "    df_per_test=pd.concat([c00,c10,c20,c30,c40,c50],axis=1)\n",
    "    df_per_test.columns = ['c0', 'c1', 'c2','c3','c4','c5']\n",
    "    #df_per_test=df_per_train.T\n",
    "    df_per_test\n",
    "\n",
    "    # Define overall RMSE variable before the loop\n",
    "    overall_rmse_per_cluster = []\n",
    "\n",
    "    # Calculate RMSE for each partition/sample data\n",
    "    \n",
    "    for i in range(6):\n",
    "        #train_df = train_dfs[i]\n",
    "        #test_df = test_dfs[i]\n",
    "        \n",
    "        # Calculate the squared errors for each cluster in each partition\n",
    "        squared_errors = (df_per_train.values) - (df_per_test.values) ** 2\n",
    "        # Calculate the mean squared error for each cluster in each partition\n",
    "        mean_squared_error = np.mean(squared_errors)\n",
    "        # Calculate the root mean squared error (RMSE) for each cluster in each partition\n",
    "        rmse_per_cluster = np.sqrt(mean_squared_error)\n",
    "        #print(f\"RMSE for partition {i+1} for each cluster:\", rmse_per_cluster)\n",
    "        # Append the RMSE for this partition to the overall RMSE list\n",
    "        overall_rmse_per_cluster.append(rmse_per_cluster)\n",
    "        \n",
    "    print(\"Sample:\",counter)\n",
    "    print(\"Training set:\",X_train.shape)\n",
    "    print(f\"Num of clusters: {len(np.unique(labels))}\") \n",
    "    counter += 1\n",
    "        \n",
    "    # Convert the overall RMSE list to a numpy array\n",
    "    overall_rmse_per_cluster = np.array(overall_rmse_per_cluster)\n",
    "    \n",
    "    # Calculate the overall RMSE by averaging the RMSEs of all clusters across all partitions\n",
    "    overall_rmse = np.mean(overall_rmse_per_cluster)\n",
    "    \n",
    "    #print(\"\\nOverall RMSE for each cluster:\", [round(val, 4) for val in overall_rmse_per_cluster])\n",
    "    print(\"\\nOverall RMSE across all clusters and partitions:\", round(overall_rmse, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
